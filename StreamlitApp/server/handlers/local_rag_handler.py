import boto3
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.prompts import PromptTemplate
import os

class LocalRAGHandler:
    def __init__(self, bucket: str, key: str):
        self.qa_chain = self._initialize_chain(bucket, key)

    def _load_documents(self, bucket, key):
        s3 = boto3.client('s3')
        obj = s3.get_object(Bucket=bucket, Key=key)
        xml_bytes = obj['Body'].read()
        root = ET.fromstring(xml_bytes)

        results = []
        for category in root.findall("Category"):
            category_name = category.get("name", "")
            subcategories = category.findall("Subcategory")

            if subcategories:
                for subcat in subcategories:
                    subcategory_name = subcat.get("name", "")
                    for item in subcat.findall("Item"):
                        title = item.findtext("Title")
                        url = item.findtext("URL")
                        content = item.findtext("Content") or ""
                        soup = BeautifulSoup(content, "lxml")
                        for dl in soup.find_all("dl"):
                            dt, dd = dl.find("dt"), dl.find("dd")
                            if dt and dd:
                                results.append({
                                    "Category": category_name,
                                    "Subcategory": subcategory_name,
                                    "title": title,
                                    "url": url,
                                    "êµ¬ë¶„": dt.get_text(strip=True),
                                    "ë‚´ìš©": dd.get_text(separator="\n", strip=True)
                                })
            else:
                for item in category.findall("Item"):
                    title = item.findtext("Title")
                    url = item.findtext("URL")
                    content = item.findtext("Content") or ""
                    soup = BeautifulSoup(content, "lxml")
                    for dl in soup.find_all("dl"):
                        dt, dd = dl.find("dt"), dl.find("dd")
                        if dt and dd:
                            results.append({
                                "Category": category_name,
                                "Subcategory": None,
                                "title": title,
                                "url": url,
                                "êµ¬ë¶„": dt.get_text(strip=True),
                                "ë‚´ìš©": dd.get_text(separator="\n", strip=True)
                            })

        texts, metadatas = [], []
        for r in results:
            if r["êµ¬ë¶„"] not in ["ë¬¸ì˜ì²˜", "ì„¤ë¬¸", "ë§Œì¡±ë„"]:
                texts.append(
                    f"ì¹´í…Œê³ ë¦¬: {r['Category'] or 'ì—†ìŒ'}\n"
                    f"ì†Œë¶„ë¥˜: {r['Subcategory'] or 'ì—†ìŒ'}\n"
                    f"ì‚¬ì—…ëª…: {r['title']}\n"
                    f"êµ¬ë¶„: {r['êµ¬ë¶„']}\n"
                    f"ë‚´ìš©:\n{r['ë‚´ìš©']}"
                )
                metadatas.append({"title": r["title"], "source": r["url"]})

        return texts, metadatas

    def _initialize_chain(self, bucket, key):
        texts, metadatas = self._load_documents(bucket, key)
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        documents = splitter.create_documents(texts, metadatas=metadatas)

        embedding = OpenAIEmbeddings(model="text-embedding-ada-002")
        vectorstore = Chroma.from_documents(documents, embedding, collection_name="semas-structured")

        prompt_template = PromptTemplate(
            input_variables=["summaries", "question"],
            template="""
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì§€ì›ì •ì±…ì— ëŒ€í•œ ì „ë¬¸ ë‹µë³€ìì…ë‹ˆë‹¤.

ë‹¤ìŒ ë¬¸ì„œëŠ” ì—¬ëŸ¬ ì§€ì›ì‚¬ì—…ë“¤ì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤.
ê° ë¬¸ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:
- ì‚¬ì—…ëª…: ë°˜ë“œì‹œ ì´ í•„ë“œì— ë‚˜íƒ€ë‚˜ëŠ” ê°’ë§Œ ì‹¤ì œ ì‚¬ì—…ëª…ìœ¼ë¡œ ê°„ì£¼í•˜ì„¸ìš”.
- êµ¬ë¶„: í•­ëª© ìœ í˜• (ì˜ˆ: ì§€ì›ë‚´ìš©, ì‹ ì²­ìê²© ë“±)
- ë‚´ìš©: í•´ë‹¹ í•­ëª©ì˜ ì‹¤ì œ ì„¤ëª…ì…ë‹ˆë‹¤.

- 'ë‚´ìš©' ì¤‘ ì¼ë¶€ í‘œí˜„(ì˜ˆ: "íì—… ì§€ì›")ì„ ì‚¬ì—…ëª…ìœ¼ë¡œ ì˜¤ì¸í•˜ì§€ ë§ˆì„¸ìš”.
- ë°˜ë“œì‹œ 'ì‚¬ì—…ëª…' í•„ë“œì˜ ê°’ë§Œ ì œëª©ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- í•´ë‹¹í•˜ëŠ” ì‚¬ì—…ì˜ 'ì‚¬ì—…ëª…'ì„ ê°•ì¡°í•œ í›„, ìƒì„¸ë‚´ìš©ì„ ê°€ëŠ¥í•œí•œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
- ë§Œì¡±ë„ ì„¤ë¬¸, ë¬¸ì˜ì²˜ ë“±ì€ ì œì™¸í•˜ê³  ì •ì±… ë‚´ìš© ìœ„ì£¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
- "ì¥ì‚¬ê°€ ì•ˆëœë‹¤", "í˜ë“¤ë‹¤", "ë§¤ì¶œì´ ì—†ë‹¤" ë“±ì˜ í‘œí˜„ì€ 'ê²½ì˜ ë¶€ì§„'ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”.

ë¬¸ì„œ:
{summaries}

ì§ˆë¬¸:
{question}

ë‹µë³€:
"""
        )

        llm = ChatOpenAI(model_name="gpt-4.1-mini", temperature=0)
        retriever = MultiQueryRetriever.from_llm(retriever=vectorstore.as_retriever(), llm=llm)

        return RetrievalQAWithSourcesChain.from_chain_type(
            retriever=retriever,
            chain_type="stuff",
            chain_type_kwargs={"prompt": prompt_template},
            llm=llm
        )

    def ask(self, question: str):
        response = self.qa_chain.invoke({"question": question})
        answer = response["answer"].strip()

        suffix = (
            "\n\n---\n\n"
            "â„¹ï¸ ë” ìì„¸í•œ ë‚´ìš©ì€ ê° ì§€ì›ì‚¬ì—…ì˜ ê³µì‹ í™ˆí˜ì´ì§€ ë§í¬ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.  \n"
            "ğŸ”— [ì†Œìƒê³µì¸ ì§€ì›ì‚¬ì—… ì•ˆë‚´](https://www.semas.or.kr/web/main/index.kmdc)"
        )
        return answer + suffix, response.get("sources")
